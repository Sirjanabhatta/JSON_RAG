{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MmqB00mbAq4J",
        "outputId": "03d46987-3568-4a69-ae54-894de455a902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-llms-gemini in /home/sirjana/anaconda3/lib/python3.11/site-packages (0.1.11)\n",
            "Requirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.5.4)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-llms-gemini) (0.10.55)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.2.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-llms-gemini) (10.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (2.32.0)\n",
            "Requirement already satisfied: protobuf in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.25.3)\n",
            "Requirement already satisfied: pydantic in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.10.12)\n",
            "Requirement already satisfied: tqdm in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2023.10.0)\n",
            "Requirement already satisfied: httpx in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.35.14)\n",
            "Requirement already satisfied: pandas in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /home/sirjana/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.9.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.63.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.9)\n",
            "Requirement already satisfied: click in /home/sirjana/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/sirjana/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2023.10.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.8.0)\n",
            "Requirement already satisfied: sniffio in /home/sirjana/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.3.0)\n",
            "Requirement already satisfied: certifi in /home/sirjana/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /home/sirjana/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.5)\n",
            "Requirement already satisfied: idna in /home/sirjana/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (3.21.3)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (4.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (2023.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (1.62.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (3.0.9)\n",
            "Requirement already satisfied: packaging>=17.0 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (23.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->llama-index-llms-gemini) (0.4.8)\n",
            "Requirement already satisfied: six>=1.5 in /home/sirjana/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-gemini) (1.16.0)\n",
            "Requirement already satisfied: jsonpath-ng in /home/sirjana/anaconda3/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: ply in /home/sirjana/anaconda3/lib/python3.11/site-packages (from jsonpath-ng) (3.11)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install llama-index-llms-gemini\n",
        "!pip install jsonpath-ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pzEczQlpBarF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = \"Your_GEMINI_Key_here\"\n",
        "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7GNAj5jwA1MX"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core.indices.service_context import ServiceContext\n",
        "from llama_index.core.indices.struct_store import JSONQueryEngine\n",
        "from llama_index.llms.gemini import Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vL8XopqLA1Of"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# Construct the paths to the JSON and schema files\n",
        "json_filepath ='/home/sirjana/JSON Answering System/data/sample.json'\n",
        "schema_filepath = '/home/sirjana/JSON Answering System/data/sample_schema.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7PAzBcPwA1Q2"
      },
      "outputs": [],
      "source": [
        "# Read the JSON file\n",
        "with open(json_filepath, 'r') as json_file:\n",
        "    json_value = json.load(json_file)\n",
        "\n",
        "# Read the schema file\n",
        "with open(schema_filepath, 'r') as schema_file:\n",
        "    json_schema = json.load(schema_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "QiSVbqetA1VT"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = os.environ['GOOGLE_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "xRZ8POCqA1XU"
      },
      "outputs": [
        {
          "ename": "InvalidArgument",
          "evalue": "400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m Gemini(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/gemini-pro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m service_context \u001b[38;5;241m=\u001b[39m ServiceContext\u001b[38;5;241m.\u001b[39mfrom_defaults(llm\u001b[38;5;241m=\u001b[39mllm)\n\u001b[1;32m      4\u001b[0m nl_query_engine \u001b[38;5;241m=\u001b[39m JSONQueryEngine(\n\u001b[1;32m      5\u001b[0m     json_value\u001b[38;5;241m=\u001b[39mjson_value, json_schema\u001b[38;5;241m=\u001b[39mjson_schema, service_context\u001b[38;5;241m=\u001b[39mservice_context\n\u001b[1;32m      6\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/llms/gemini/base.py:141\u001b[0m, in \u001b[0;36mGemini.__init__\u001b[0;34m(self, api_key, model, temperature, max_tokens, generation_config, safety_settings, callback_manager, api_base, transport, model_name, **generate_kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m final_gen_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbase_gen_config}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\n\u001b[1;32m    136\u001b[0m     model_name\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    137\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mfinal_gen_config,\n\u001b[1;32m    138\u001b[0m     safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m    139\u001b[0m )\n\u001b[0;32m--> 141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_meta \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mget_model(model)\n\u001b[1;32m    143\u001b[0m supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_meta\u001b[38;5;241m.\u001b[39msupported_generation_methods\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerateContent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_methods:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/generativeai/models.py:54\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(name, client, request_options)\u001b[0m\n\u001b[1;32m     52\u001b[0m name \u001b[38;5;241m=\u001b[39m model_types\u001b[38;5;241m.\u001b[39mmake_model_name(name)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_base_model(name, client\u001b[38;5;241m=\u001b[39mclient, request_options\u001b[38;5;241m=\u001b[39mrequest_options)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtunedModels/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_tuned_model(name, client\u001b[38;5;241m=\u001b[39mclient, request_options\u001b[38;5;241m=\u001b[39mrequest_options)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/generativeai/models.py:93\u001b[0m, in \u001b[0;36mget_base_model\u001b[0;34m(name, client, request_options)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase model names must start with `models/`, got: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_model(name\u001b[38;5;241m=\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options)\n\u001b[1;32m     94\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;241m.\u001b[39mto_dict(result)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_types\u001b[38;5;241m.\u001b[39mModel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresult)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/model_service/client.py:790\u001b[0m, in \u001b[0;36mModelServiceClient.get_model\u001b[0;34m(self, request, name, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[1;32m    791\u001b[0m     request,\n\u001b[1;32m    792\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    794\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    795\u001b[0m )\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    294\u001b[0m     target,\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[1;32m    296\u001b[0m     sleep_generator,\n\u001b[1;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[1;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[1;32m    299\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[1;32m    154\u001b[0m         exc,\n\u001b[1;32m    155\u001b[0m         deadline,\n\u001b[1;32m    156\u001b[0m         sleep,\n\u001b[1;32m    157\u001b[0m         error_list,\n\u001b[1;32m    158\u001b[0m         predicate,\n\u001b[1;32m    159\u001b[0m         on_error,\n\u001b[1;32m    160\u001b[0m         exception_factory,\n\u001b[1;32m    161\u001b[0m         timeout,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n]"
          ]
        }
      ],
      "source": [
        "llm = Gemini(model=\"models/gemini-pro\")\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm=llm)\n",
        "nl_query_engine = JSONQueryEngine(\n",
        "    json_value=json_value, json_schema=json_schema, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "4n7yxcK8A1d4",
        "outputId": "7e48402c-39e2-491b-9bcb-b874ad785ef7"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"What is the department of John Doe?\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goz06vkJA1gJ"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"How many leaves has John Doe taken?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "O0innbKyA1ia",
        "outputId": "35048b8c-900b-4fce-9b5e-6ff042e64f5c"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhrPUb7_QSwa"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"Provide details of all leaves taken by Jane Smith.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "TDiKYVaXA1kX",
        "outputId": "dd859bb8-4f33-4140-df89-89c84412977f"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTP1L_DHA1mn"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"Which employees have taken annual leave?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "_g_uG2cbI_aK",
        "outputId": "5a4b5fe8-b2b1-4985-e0d1-094d615ffc88"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epcR-dSrIBiS"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"When did John Doe take his annual leave?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "uDgtltzFIBng",
        "outputId": "419e78b7-2839-4b9a-ebb8-639fb3450e1e"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-Zq_AKZIBr-"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"List all leave IDs for John Doe.\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "py4s3K6PIBwn",
        "outputId": "81ae435f-12ec-4309-dc55-27836b10e186"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response:{nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rh_Czqp5IB1X"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"What is the total number of employees in given json?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "JCG5NlanF5pc",
        "outputId": "4647843e-d16c-4dc2-9e62-1726acfef9cf"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WIPgb-JIB4p"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"What is the reason for Jane Smith was on leave on 2023-02-05?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "9bQW4ykdIB7M",
        "outputId": "fd18657e-f537-4d76-cc89-f3f185b6fdbd"
      },
      "outputs": [],
      "source": [
        "\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7xoQ5WIB9p"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"What are the leaves taken by Jane Smith?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIHCuMFtICAD"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"What are the leaves taken by Jane Smith?\",\n",
        ")\n",
        "display(Markdown(f\"Generated Response: {nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w_jYxDLICCf"
      },
      "outputs": [],
      "source": [
        "In this blog, we will explore about how to build a JSON question answering system using LlamaIndex and Gemini. In this post, we will see how these powerful tools can simplify querying JSON data, making it easy to extract valuable insights and information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOt8mZF_ICFF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_g6VOEeICHk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwPqhbpzICKz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYQ13NduICNk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPeAz-c7ICQM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ionYVJCNI_cc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK97K74RI_fN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIhfn0vFI_hH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP2eF524I_l4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8iEM_2wI_ob"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNHkqQFZI_rJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdlPzD9DI_tn",
        "outputId": "0026ceed-76e9-44e5-ff1a-477763f59233"
      },
      "outputs": [],
      "source": [
        "\n",
        "# First, install the jsonpath-ng package which is used by default to parse & execute the JSONPath queries.\n",
        "!pip install jsonpath-ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40X-JRPEI_wQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q openai\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U00VkBPGI_yv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqo6a9ixI_0_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"AIzaSyBXS4QWkjGqAxeLiFz4KoGaUnu4wO_nfiI\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfdIm488I_32"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcGMSFjRB89O",
        "outputId": "418603b0-20e4-4dbd-b1fd-ab5cafbe853f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W88fR5NfI_6b"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "\n",
        "# Specify the folders containing the JSON and schema files\n",
        "json_folder = '/content/drive/MyDrive/data'\n",
        "schema_folder = '/content/drive/MyDrive/data'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkJOT82zI_9H"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Specify the filenames of the JSON and schema files\n",
        "json_filename = 'cake.json'\n",
        "schema_filename = 'schema.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3iqUWRvI__f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Construct the paths to the JSON and schema files\n",
        "json_filepath = os.path.join(json_folder, json_filename)\n",
        "schema_filepath = os.path.join(schema_folder, schema_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-HiNkgiJACI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read the JSON file\n",
        "with open(json_filepath, 'r') as json_file:\n",
        "    json_value = json.load(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynaoYt3yJAFB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Read the schema file\n",
        "with open(schema_filepath, 'r') as schema_file:\n",
        "    json_schema = json.load(schema_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YDbCwf3JAHv",
        "outputId": "6b97df5d-9910-4269-a775-892b865e5230"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from llama_index.core.indices.service_context import ServiceContext\n",
        "from llama_index.core.indices.struct_store import JSONQueryEngine\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "service_context = ServiceContext.from_defaults(llm=llm)\n",
        "nl_query_engine = JSONQueryEngine(\n",
        "    json_value=json_value, json_schema=json_schema, service_context=service_context\n",
        ")\n",
        "raw_query_engine = JSONQueryEngine(\n",
        "    json_value=json_value,\n",
        "    json_schema=json_schema,\n",
        "    service_context=service_context,\n",
        "    synthesize_response=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "VvJ34PXWJAKV",
        "outputId": "634bda5b-554c-4aa1-e9ad-93269f6a923d"
      },
      "outputs": [],
      "source": [
        "nl_response = nl_query_engine.query(\n",
        "    \"what is the price of donut cake?\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9Ayd0eaJAPo"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"Natural language Response{nl_response}\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAy-NcVGA1ph"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjdQ3dbDA1ug"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
